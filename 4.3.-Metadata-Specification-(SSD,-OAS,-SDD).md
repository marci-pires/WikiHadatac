This section describes the three semantic metadata specifications used to describe a study's data content: Semantic Study Design (SSD), Object Access Specification (OAS), and Semantic Data Dictionary (SDD). 

Metadata specifications should conform to a set of rules. These rules, which are also called "verification rules", can apply locally to each individual metadata specification or collectively in the context of one study. Local-level verification rules are listed within the description of each metadat specification. Study-level verifications rules are described in Section 4.3.4.     

## 4.3.1. Semantic Study Design (SSD)

### 4.3.1.1. When to Use an SSD  
Semantic Study Designs are required when the structure of the study affects the understanding and quality of the data acquired from the study. The structure of a study is mainly composed of objects related to the study and relations between these objects. Objects like subjects, samples, locations and events identified during the design of a study are strong candidates to go inside of an SSD file. Objects like subjects and samples are called domain objects and may have relevant relationships between them, for example, when samples are from the subjects. Objects like events may be used to identify when subjects are under observation or when samples are collected. Objects like locations may be used to identify when and where subjects are under observation. Locations may also be the objects that are sample, for instance, when locations are from an open environment of an indoor ambience. 

### 4.3.1.2. How to Build an SSD
Inspecting written descriptions of a study is an effective main way of acquiring knowledge relevant to SSDs. Interviewing with study's designers, e.g., Principal Investigator(s), is another way of learning how a study is structured. By inspecting available documentation and knowledge about a given study, one should be able to follow the four-step process described below to construct a study's SSD:

**Step 1: Identify Semantic Object Collections (SOC)**  
Objects with explicitly assigned identifiers are strong candidates to be grouped into Semantic Object Collections (SOCs). For example, _Participant IDs (PIDs)_ are assigned to subjects, we expect that at least one SOC is created for subjects. If subjects are separated into groups, it is possible to encode each subject group as a new SOC. Further, let say that samples are collected from these subjects, and that _Sample IDs (SIDs) are assigned to these samples. These samples may become new SOCs as well.

In the table below we show the __SSD sheet__ of an SSD for __Study A__. In the first row below the header, we have a definition of the study supported by this SSD. The URI of the study is often given by the STD file feeding study's info HADatAc. The rows below the study row are the two SOCs of Study A: __kb:SOC-SUBJECTS__ and __kb:SOC-SAMPLES__. The first column of the __SSD sheet__ identifies other SSD sheets where _object specific_ information can be found for each semantic object collection.  

sheet |	hasURI	| type	| hasSOCReference | comment | label | definition | groundingLabel | isMemberOf | hasScope | hasTimeScope | hasSpaceScope | cardinality | role | basetime | source
----- | ------- | ----- | --------------- | ------- | ----- | ---------- | -------------- | ---------- | --------------- | ------------ | ------------- | ----------- | ---- | --------- | ---------------  
| | kb:STD-A | hasco:Study | | | | | | | |  
#SOC-SUBJECTS | kb:SOC-SUBJECTS	| hasco:SubjectGroup | ??child | child, the main subject of the study | Child | persons |  | kb:STD-A | | | | 6 | ont:isSubjectOf   
#SOC-SAMPLES | kb:SOC-SAMPLES | hasco:SampleCollection | kb:STD-A | kb:SOC-SUBJECTS | | | 1 | ont:isSampleOf | ??sample |    

__Reference__ is the name used mainly in SDDs to refer to semantic object collections defined in an SSD. For example, let say that objects of type children are defined in one SSD's SOC, while objects of type mothers are defined in SDDs instead of SSD. In this case, it is important for mothers to be related to the children, which is possible because the SDD can refer to objects defined in SSD.

Certain categories of objects are well defined by a given term, while others depend of their relationship to other objects. For instance, in some studies, the terms "Child" and "Mother" may be complete and precise enough for scientists involved with these studies to fully identify the nature of these objects of concern. These terms are called __Grounding Labels__ for their corresponding SOCs. Within the same studies, the term "Sample" may not be complete enough to identify the nature of sample objects: for example, these objects may be samples from a child, or samples from a mother, and it is important to say something like "Mother's Sample" than just "Sample". In this case, the SOCs of Children and Mothers are grounded by the terms "Child" and "Mother", while the SOC Sample may not have any grounding label. In this case, it is important for non-grounded objects to be logically connected to one grounded object.

**Step 2: Identify Relationships Among SOCs**  
Relationships between SOCs can vary greatly from one study to another, that is one of the main reasons why a study may need to use an SSD file instead of using simpler PID and MAP files to describe its objects. When building a SSD, we need to identify relationships between SOCs identified in Step 1. 

In the SSD in Step 1, we observe that the __hasScope__ of samples is subjects collection (i.e., __kb:SOC-SUBJECTS__). We further see that the subject's cardinality is 6 and that the sample's cardinality is 1. Since subjects are not in the scope of any other SOC, the exact number of subjects is its cardinality of 6. Since samples are in the scope of subjects, the cardinality means that the SOC expects to have one sample for each subject (1 x 6) for a total of six samples.

The role's column specifies the role of study objects. The SSD specifies __ont:isSubjectOf__ meaning that each object is a __ont:isSubjectOf__ the object representing the study since subjects are not in the scope of any other SOC. For samples, however, we observe that each sample is __ont:isSampleOf__ of a subject object. These mappings are further specified in the object-level sheets of the SSD.

SDD is described in [Section 3.4.2.1](https://github.com/paulopinheiro1234/hadatac/wiki/4.3.-Metadata-Specification-(SSD,-OAS,-SDD)#433-semantic-data-dictionary-sdd).

**Step 3: Identify Study Objects for each SOC**  

The table below shows the __#SUBJECT__ sheet describing the study objects inside of __kb:SOC-SUBJECTS__. The sheet contains a list of the study-specific identifier and type of each object in the collection. Objects in the list specified for positions beyond the cardinality specified for the SOC are ignored. 

orignalID | rdf:type 
--- | -------- 
10001 | sio:Human
10002 | sio:Human
10003 | sio:Human
10004 | sio:Human
10005 | sio:Human
10006 | sio:Human

**Step 4: Mapping Study Objects from Related SOCS**  

The table below shows the __#SAMPLE__ sheet describing the study objects inside of __kb:SOC-SAMPLES__. The sheet contains a list of the study-specific identifier and type of each object, plus one _hasScopeID. This extra column is needed to map each sample to each subject. Broadly speaking, one hasScopeID is needed for each scope identified in the SDD sheet of the SDD. 

originalID | rdf:type | hasScopeID
---------- | -------- | ----------
U000001	| kb:Urine | 10001	
U000002	| kb:Urine | 10002	
U000003	| kb:Urine | 10003	
U000004	| kb:Urine | 10004	
U000005	| kb:Urine | 10005	
U000006	| kb:Urine | 10006	

### 4.3.1.3. SSD Verification Rules

#### SSD-Level Rule 1    
There must be a sheet named "SSD" in the SSD file which contains the object collection (OC) level definitions and relations.   
__Consequence of breaking the rule__:  HADatAc will stop processing the SSD file and an error message will be raised in the LOG file.  
__Error message__: “Missing SSD sheet in the xxx (name of the SSD) file.”  
__Correction__: check if the indicated DASA in the DM is correctly defined with attribute-object relationships 

#### SSD-Level Rule 2    
The SSD should not contain special characters that can not be parsed (non-ASCII), cells with only white spaces and invisible extra rows.  
__Consequence of breaking the rule__:  HADatAc will stop processing the SSD file and an error message will be raised in the LOG file.  
__Error message__: “Row "XXX" and Cell "XXX" contains illegal content that can not be parsed.”  
__Correction__: Either update or delete the illegal content. 

#### SSD-Level Rule 3    
The "sheet" column in the "SSD" sheet are synced with the other sheet names in the SSD.  
__Consequence of breaking the rule__:  HADatAc will stop processing the SSD file and an error message will be raised in the LOG file.  
__Error message__: “The "XXX" sheet can not be found in the SSD.”  
__Correction__: Check if the "sheet" column in the "SSD" sheet are synced with the other sheet names in the SSD. 

#### SSD-Level Rule 4    
Namespaces of URIs used in the SDD must be registered in HADatAc.  
__Consequence of breaking the rule__:  HADatAc will stop processing the SSD file and an error message will be raised in the LOG file.  
__Error message__: “The following namespaces in the Dictionary Mapping has unregistered namespace in cells: xxx”  
__Correction__: If the namespace is misspelled, correct it. If the namespace is correct, verify if it is included in namespaces.properties  

#### SSD-Level Rule 5    
The OC sheets that contain Study Objects should follow the schema "originalID,rdf:type,scopeID,timeScopeID"  
__Consequence of breaking the rule__:  HADatAc will stop processing the SSD file and an error message will be raised in the LOG file.  
__Error message__: “originalID/rdf:type/scopeID/timeScopeID can not be found”.  
__Correction__:    

## 4.3.2. Object Access Specification (OAS) 

### 4.3.2.1. OAS Elements

OAS specifications identify resources necessary for processing content of CSV files. An OAS is a CSV file itself composed of one row of data (i.e., a record) composed of the following eight fields (columns):

Column Header   | Column Description
--------------- | ------------------
Study ID        | study 
da name         | a name-template for selecting incoming files 
data dict       | the data dictionary of choice for processing the file(s)
deployment uri  | URI of deployment originating data file's content 
cell scope      | cell level scope (see explanation below in this section)
owner email     | the email address of the person who is the actual owner of the data 
permission url  | permission policy for accessing the data

The data dictionary of the OAS identifies the SDD document that describes how objects identified during the parsing of the SDD file content map to object types. The precise identification of which object is mapped to each value is specified by the row-scope attribute and cell-scope attribute described below. 

### 4.3.2.2. Object Scoping

Objects need to be either instantiated of located in HADatAc's knowledge base to have values of their properties updated. 
Object scoping is needed for objects that already exists HADatAc, for example, objects created by SSD files. 

**Cell Scope**

The cell scope is a value assignment strategy used when values in rows of CSV files cannot be uniquely mapped to a single object type as combinations of direct and indirect attributes of the object type. In other words, cell scope is used when objects in a row belong to multiple objects that are not associated with each other through known semantic relationships. 

One special use of cell scope is when all the attributes of interest in a given file come from a single object. In this case, OAS allows the use of an asterisk (__*__) to represent all the attributes in the SDD. For example, if all the attributes in a given file are from kb:SUB07, the OAS for such file would be __cell-scope="<<*, kb:SUB07>>"__.

### 4.3.2.3. An OAS Example

Let assume that we have three files names DA-demographics001.csv, DA-demographics002.csv and DA-demographics003.csv, that the three files need to be processed by a common SDD named SDD-demographics.xsl, and that the data files are related to a common set of objects. Under these assumptions, one OAS file can be used to assign how content extracted from the files will be assigned to the common set of objects. 

Study ID  | da name      | data dict        | deployment uri | cell scope | owner email     | permission uri
--------- | ------------ | ---------------- | -------------- | ---------- | --------------- | --------------
2016-1234 | demographics | SDD-demographics | proj:quest     |            | joe@example.org | http://example\#team

The table above shows an example of how a semantic dada dictionary SDD-demographics is assigned to parse the content of the file starting with the name __DA-demographics__. In fact, the OAS specification assumes that any data file name starts with __DA-__ plus the data-file-name value in the OAS.  

The OAS above further specifies that joe@example.org is the email of the owner of the data content of any file that starts with the name __DA-demographics__, and that anyone with permission __http://example#team__ (according to HADatAc's data access policy) has access to content extracted from any file matching the data-file-name identified in the OAS.

## 4.3.3. Semantic Data Dictionary (SDD)

### 4.3.3.1. When to use an SDD

SDDs semantically describe the content of a tabular data file. Without an SDD, HADatAc does not know how to extract the content (both data and metadata) from a data file and to move it into a queryable data repository. For each column header listed in an SDD, the document minimally specifies the kind of attribute of that column, and the object that has that property. For example, the attribute may be Height and the object may be a human who is a subject in a given study.

It is important to note that SDDs are not necessarily designed for a single study, and that there are many examples of SDDs that can be reused multiple times. For instance, one SDD may be developed to describe the output of a sensor or instrument, and that same SDD can be used in any study that uses that same kind of sensor. Moreover, the SDD may be developed to describe data files produced by using an standardized questionnaire, and should be able to be used in any study that uses that standardized questionnaire.

### 4.3.3.2. How to Build SDD

The SDD is made up of five tables: __InfoSheet__, __Dictionary Mapping__, __Code Mapping__, __Timeline__, and __Codebook__.

**Infosheet**  
The Infosheet is used to organize the other four tables named above. An example Infosheet template is shown below.

Attribute       |	Value
--------------- | ------------
SDD_Name	| Name
Dictionary_Mappings | #DICT
Codebook	| #CODEBOOK
Code_Mappings	| #CODEMAPPING
Timeline	| #TIMELINE
Imports	        | http://example.org/myontology/

We often encode SDDs using either a collection of Google Documents or a single Excel Spreadsheet. When using Google Docs, the values in the InfoSheet are URLs to other Google Docs containing the corresponding SDD specification. In Excel, we use the __#__ sign followed with the name of the sheet within the Spreadsheet that contains the corresponding SDD specification. 

**Dictionary Mappings**  

The bulk of the SDD specification is done using the Dictionary Mapping Table, which is used to annotate the columns of a given dataset. The SDD Data Model (DM) Specification is shown below.

DM              | Column                |	Description
--------------- |  -------------------- | --------------------------- 
Attribute	| rdf:type	        | Class of attribute entry
attributeOf	| sio:isAttributeOf	| Entity having the attribute
Column		| Entry                 | column header in dataset
Comment	        | rdfs:comment	        | Comment for the entry
Definition	| skos:definition	| Entry text definition
Entity	        | rdf:type	        | Class of entity entry
Format	        |	                | Specifies the structure of the Unit value
inRelationTo	| sio:inRelationTo	| Entity that the role is linked to
Label	        | rdfs:label	        | Label for the entry
Relation        |		        | Custom relation that replaces inRelationTo
Role	        | sio:hasRole	        | Type of the role of the entry
Time	        | sio:existsAt	        | Time point of measurement
Unit	        | sio:hasUnit	        | Unit of Measure for entry
wasDerivedFrom	| prov:wasDerivedFrom	| Entity from which the entry was derived
wasGeneratedBy	| prov:wasGeneratedBy	| Activity from which the entry was produced

**Codebook**  
The Codebook table contains possible values of coded variables and their associated labels. For variables with discrete values, when appropriate, we augment each possible value with mappings to corresponding concepts, as shown in the table below.

Column	| Code |	Label	| Class
------- | ---- | -------------- | -----
race	| 0	| white	  | kb:White
race	| 1	| black	  | kb:AfricanAmerican
race	| 2	| other	  | kb:OtherRace
smoke	| 0	| no smoking |	kb:NonSmoker
smoke	| 1	| some smoking | kb:Smoker

**Timeline**  
Customized time intervals can be specified in the Timeline sheet, which can be used to annotate the corresponding class and unit related to a given entry, as well start and end times of an event, and a connection to concepts that the entry may be related to. An example timeline is shown below.

Name	| Label	        | Type     | Start | End   | Unit     |	inRelationTo
------- | ------------- | -------- | ------| ----- | -------- | ------------------- 
??visit1 |	Visit 1	| kb:Visit | 10.1  | 19.9  | sio:Week | ??baseline
??visit2 |	Visit 2	| kb:Visit | 20.0  | 32.0  | sio:Week | ??baseline

### 4.3.3.3. SDD Verification Rules

#### SDD-Level Rule 1 
Semantic Data Dictionary (SDD) must contain an info sheet  
__Consequence of breaking the rule__:  HADatAc will stop processing the SDD  
__Error message__: “The Info sheet is missing in this SDD file.”  
__Correction__: The user should add an info sheet as the first sheet into the SDD file.  

#### SDD-Level Rule 2 
If SDD contain the following sheets: DataDictionary, CodeBook, TimeLine, and CodeMapping  
__Consequence of breaking the rule__:  HADatAc will skip reading the File and generate an error message but will not stop processing the SDD except for missing dictionaryFile.
__Error messages__: “The CodeMapping is missing” or “The DataDictionary is missing.” or “The Codebook is missing.” or ”The TimeLine is missing”  
__Correction__: The user should check if the missing sheet(s) is(are) needed. The DataDictionary must be included under any circumstance.

#### SDD-Level Rule 3  
InfoSheet cannot be empty  
__Consequence of breaking the rule__:  HADatAc will stop processing the SDD  
__Error messages__: “InfoSheet is empty”  
__Correction__: Add the info sheet content.  

#### SDD-Level Rule 4  
The DataDictionary sheet in the SDD cannot be empty  
__Consequence of breaking the rule__:  HADatAc will stop processing the SDD  
__Error messages__: “The DataDictionary sheet is empty”  
__Correction__: The user should check why the DataDictionary is empty in the SDD file and add correct content into data dictionary sheet.  

#### SDD-Level Rule 5  
URIs in SDDs must be resolvable against existing knowledge graph  
__Consequence of breaking the rule__:  HADatAc will generate an error message and will not stop processing the SDD  
__Error message__: “The following URIs in the Dictionary Mapping are unresolvable: <list of URIs>"  
__Correction__: Identify if the URI is available in its original content. Correct the URI if it is misspelled. Stop using the URI in the SDD if it does not exist.   

#### SDD-Level Rule 6  
Namespaces of URIs used in the SDD must be registered in HADatAc  
__Consequence of breaking the rule__:  HADatAc will generate an error message and will not stop processing the SDD  
__Error message__: “The following namespaces in the Dictionary Mapping has unregistered namespace in cells: xxx”  
__Correction__: If the namespace is misspelled, correct it. If the namespace is correct, verify if it is included in namespaces.properties

#### SDD-Level Rule 7  
HADatAc special attributes are:  
* sio:TimeStamp  
* sio:TimeInstant  
* hasco:namedTime  
* hasco:originalID  
* hasco:uriId  
* hasco:hasMetaEntity  
* hasco:hasMetaEntityURI  
* hasco:hasMetaAttribute  
* hasco:hasMetaAttributeURI  
* hasco:hasMetaUnit  
* hasco:hasMetaUnitURI  
* sio:InRelationTo  
* hasco:hasLOD  
* hasco:hasCalibration  
* hasco:hasElevation  
* hasco:hasLocation   

Non-special attributes are called _ordinary attributes_. Every ordinary attribute must have a path to a subclass of hasco StudyIndicator  
__Consequence of breaking the rule__: HADatAc will generate an error message and will not stop processing the SDD  
__Error message__: “"The Attributes: xxx is not associated with any hasco:StudyIndicator.”  
__Correction__: Change the domain ontology to associate the attribute(s) to study indicators, or check if the ontology loaded is complete  

#### SDD-Level Rule 8 
if DASAs and DASOS derived from an Excel SDD are well-formed (constains non ASCII chars)  
__Consequence of breaking the rule__: HADatAc will generate an error message and will not stop processing the SDD  
__Error message__: “The Dictionary Mapping has incorrect content in : xxx”  
__Correction__: check if the content in the indicated cells contain illegal characters  

## 4.3.4 Study-level Verification Rules

### Study-Level Rule 1    
Each ordinary attribute in an SDD must have a path in the knowledge graph directly or indirectly connecting it to an object defined in the SSD that has a grounding label   
__Consequence of breaking the rule__:  HADatAc will not be able to use the SDD for ingesting data  
__Error message__: “xxx has study object path : xxx - xxx - xxx”  
   “xxx has has no study object path !”  
__Correction__: check if the indicated DASA in the DM is correctly defined with attribute-object relationships  

