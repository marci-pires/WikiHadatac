Metadata content is added into HADatAc through the use of online forms or through the uploading and ingestion of content files. Content files can further be added manually or automatically.  

Name conventions are required for automated ingestion of content file. Files that do not follow name conventions can only be further processed if manual commands are issued to identify file content as well as any additional information that may be needed to enable a proper ingestion of content files.

If some anomaly occurs during the processing of any files, whether the file is supposed to be processed manually or automatically, the file will be put on hold and an error message will appear in the file log. The log is visible on-line.

## 3.4.1. Inserting Metadata Content Manually

Study information including study objects and their semantic object collections can be added manually inside of home > Manage Studies.

Deployment, Platform, Instrument and Detector information can be added manually inside of home > Manage Deployments.

SDD information can be added manually inside of home > Manage Data Acquisition Schema.

## 3.4.2. Inserting Metadata Content Automatically

### 3.4.2.1. Types of Metadata Content Files

For each one of the metadata content files below, we will identify their name convention, description, and possible error messages generated during their ingestion. Error messages are in the file's log that is displayed when selecting the "log" button on "HADatAc Home > File Management". 
  
**Deployment (DPL) Files**

Name convention: Name starts with: __DPL-__. Ends with __.xlsx__

Used to include platform, instrument, detector and deployment information into HADatAc. The information in this kind of file tends to be study independent in the sense that platforms, instruments and detectors can be used in multiple studies. 

**Study (STD) Files**

Name convention: Name starts with: __STD-__. Ends with __.xlsx__ or __.csv__

Used to include one or more study basic information into HADatAc. Information in STD files include things like PI's name and address. Study's aims, short description and long description.

**Semantic Study Design (SSD) Files**

Name convention: Name starts with: __SSD-__. Ends with __.xlsx__

Used to specify and identify object collections related to studies. Subjects and samples are examples of such collections. Inter-relationship among object collections are also specified in SSD files. For example, if the main group of subjects are infants, and the group of parents is another group, SSD can specify the objects in both collections, and specify how parents are mapped to infants. Instructions on how to generate SSD files are available in [Section 4.3.1](https://github.com/paulopinheiro1234/hadatac/wiki/4.3.-Metadata-Specification-(SSD,-OAS,-SDD)#431-semantic-study-design-sdd).

**Semantic Data Dictionary (SDD) Files**

Name convention: Name starts with: __SSD-__. Ends with __.xlsx__

Used to guide the process of ingesting file content into HADatAc databases. A single SDD file can be used to ingest the content from multiple files as long these files share the same content type.  Instructions on how to generate SSD files are available in [Section 4.3.3](https://github.com/paulopinheiro1234/hadatac/wiki/4.3.-Metadata-Specification-(SSD,-OAS,-SDD)#433-semantic-data-dictionary-sdd). 

**DA Files**

Name convention: Name starts with: __DA-__. Ends with __.csv__

These are the actual data files with the content that is semantically annotated and added into the SOLR repository. If a data files is not

**OAS Files**

Name convention: Name starts with: __OAS-__. Ends with __.xlsx__ or __.csv__

OAS files are to identify a common ‘prefix’ that is assigned to a given collection of data files. For instance, if File1.csv and File2.csv both can use SDD-Z.xls, then we can create an OAS file saying that ‘DA-Z’ is the prefix for SDD-Z.xls. In this case, we could rename File1 into DA-Z-1 and File2 into DA-Z-2 enabling the use of a common SDD to ingest both files.

OAS Files are also used to assign files to studies and to a given owner. Thus, we need an OAS file for each collection of files (including collections of 1 file) that share the same properties:
* Type of data content
* Owner
* Study that it belongs to

Instructions on how to generate OAS files are available in [Section 4.3.2](https://github.com/paulopinheiro1234/hadatac/wiki/4.3.-Metadata-Specification-(SSD,-OAS,-SDD)#432-object-access-specification-oas). 

Error messages:
- __"Error in DataAcquisitionGenerator: The specified owner email admin@hadatac.org is not a valid user!"__: this means that the email in the ACQ file does not match the email address of any user registered in HADatAc as described in Section 5.2.3.

### 3.4.2.2. Ingestion Workflow

The exact way metadata files are fed into HADatAc may vary by application. Moreover, some studies may make use of SSDs while others may make use of PID, SID and MAP files. 

Below, we describe a partial order of events that must be observed in automated workflows feeding metadata content into HADatAc __based on PID, SID and MAP files__:

* STD files can be submitted any time
* SDD files can be submitted any time
* PID files can be submitted before all the STD of studies listed in the file have been submitted and ingested (it is normally easy to have one PID file feeding PIDs of subjects from a single study) 
* SID files can be submitted before all the STD of studies listed in the file have been submitted and ingested (it is normally easy to have one SID file feeding SIDs of samples from a single study)
* MAP files can be submitted after all the PIDs and SIDs listed inside the file have been submitted and ingested
* ACQ files can be submitted after the following: STD of associated DA file have been submitted and ingested; SDD of associated DA file have been submitted and ingested
* DA files can be submitted after corresponding ACQ file have been submitted and ingested   

Below, we describe a partial order of events that must be observed in automated workflows feeding metadata content into HADatAc __based on SSD files__:

* STD files can be submitted any time
* SDD files can be submitted any time
* SSD files can be submitted before the STD of the study has been submitted and ingested 
* OAS files can be submitted after the following: STD of associated DA file have been submitted and ingested; SDD of associated DA file have been submitted and ingested
* DA files can be submitted after corresponding ACQ file have been submitted and ingested   

In the tasks above, it is said that files need to be submitted and ingested meaning that automated workflows should be able to verify that the ingestion of a given metadata file submitted into HADatAc was successful. This verification is accomplished through the use of the RESTFul service described below. 

### 3.4.2.3. Examples of Content File Uploading for Studies

**A Simple scenario**

Let assume the following for study X: 
* X has 100 subjects
* X has 200 samples corresponding to 2 samples per subject
* A single file is submitted with the EPI data for the 100 subjects
* A single file is submitted with the Lab data for the 200 samples

This is the summary of data files for X:
* FileSubject.csv with EPI data about the 100 subjects
* FileSample.csv with Lab data about the 200 samples

In terms of type of file content:
* FileSubject.csv‘s type of content conforms to SDD-Subject
* FileSample.csv’s type of content conforms to SDD-Sample

This is what is needed: 
* Create one ACQ file (ACQ-X-Subject.csv) that maps the name ‘DA-X-subject’ to SDD-Subject and submit both SDD-Subject and ACQ-X-Subject.csv right away into HADatAc
* Create another ACQ file that maps the name ‘DA-X-sample’ to SDD-Sample and submit it right away into HADatAc
* Rename FileSubject.csv to ‘DA-X-subject.cvs’ and submit it into HADatAc after submitting its corresponding ACQ file 
* Rename FileSample.csv to ‘DA-X-sample.csv’ and submit it into HADatAc after submitting its corresponding ACQ file 

**A more complex scenario** 

Let assume the following for study Y: 
* Y has 100 subjects
* Y has 200 samples corresponding to 2 samples per subject
* A sample is collected from each subject at Visit1 and the second sample is collected from each subject at Visit2
* Y’s PI decided to submit 2 EPI files, one EPI file with demographic data about the 100 subjects, and the other EPI file with anthropometric  for the same subjects

This is the summary of data files for Y:
* FileA.csv with demographic data
* FileB.csv with anthropometric data
* FileC.csv with Lab data about 100 samples collected during Visit1 of each subject
* FileD.csv with Lab data about the other 100 samples collected during Visit2 of each subject

In terms of type of file content:
* Files A and B have different types of content, which conforms to SDD-1 and SDD-3
* Files C and D have the same type of content, which conforms to SDD-2

This is what is needed: 
* Create one ACQ file (ACQ1.csv) that maps the name ‘DA-type1’ to SDD-1 and submit both SDD-1 and ACQ1.csv right away into HADatAc
* Create another ACQ file that maps the name ‘DA-type2’ to SDD-2 and submit it right away into HADatAc
* Create another ACQ file that maps the name ‘DA-type3’ to SDD-3 and submit it right away into HADatAc
* Rename File A to ‘DA-type1-A.cvs’ and submit it into HADatAc after 
* Rename File B to ‘DA-type3-B.csv’
* Rename File C to ‘DA-type2-C.csv’
* Rename File D to ‘DA-type2-D.csv’

